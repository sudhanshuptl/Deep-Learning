{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIAkIlfmCe1B"
   },
   "source": [
    "# The Hello World of Deep Learning with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA93WUy1zzWf"
   },
   "source": [
    "Like every first app you should start with something super simple that shows the overall scaffolding for how your code works. \n",
    "\n",
    "In the case of creating neural networks, the sample I like to use is one where it learns the relationship between two numbers. So, for example, if you were writing code for a function like this, you already know the 'rules' — \n",
    "\n",
    "\n",
    "```\n",
    "float hw_function(float x){\n",
    "    float y = (2 * x) - 1;\n",
    "    return y;\n",
    "}\n",
    "```\n",
    "\n",
    "So how would you train a neural network to do the equivalent task? Using data! By feeding it with a set of Xs, and a set of Ys, it should be able to figure out the relationship between them. \n",
    "\n",
    "This is obviously a very different paradigm than what you might be used to, so let's step through it piece by piece.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzbtdRcZDO9B"
   },
   "source": [
    "## Imports\n",
    "\n",
    "Let's start with our imports. Here we are importing TensorFlow and calling it tf for ease of use.\n",
    "\n",
    "We then import a library called numpy, which helps us to represent our data as lists easily and quickly.\n",
    "\n",
    "The framework for defining a neural network as a set of Sequential layers is called keras, so we import that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9uIpOS2zx7k"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwJGmDrQ0EoB"
   },
   "source": [
    "## Define and Compile the Neural Network\n",
    "\n",
    "Next we will create the simplest possible neural network. It has 1 layer, and that layer has 1 neuron, and the input shape to it is just 1 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQFAr_xo0M4T"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhjZjZ-c0Ok9"
   },
   "source": [
    "Now we compile our Neural Network. When we do so, we have to specify 2 functions, a loss and an optimizer.\n",
    "\n",
    "If you've seen lots of math for machine learning, here's where it's usually used, but in this case it's nicely encapsulated in functions for you. But what happens here — let's explain...\n",
    "\n",
    "We know that in our function, the relationship between the numbers is y=2x-1. \n",
    "\n",
    "When the computer is trying to 'learn' that, it makes a guess...maybe y=10x+10. The LOSS function measures the guessed answers against the known correct answers and measures how well or how badly it did.\n",
    "\n",
    "It then uses the OPTIMIZER function to make another guess. Based on how the loss function went, it will try to minimize the loss. At that point maybe it will come up with somehting like y=5x+5, which, while still pretty bad, is closer to the correct result (i.e. the loss is lower)\n",
    "\n",
    "It will repeat this for the number of EPOCHS which you will see shortly. But first, here's how we tell it to use 'MEAN SQUARED ERROR' for the loss and 'STOCHASTIC GRADIENT DESCENT' for the optimizer. You don't need to understand the math for these yet, but you can see that they work! :)\n",
    "\n",
    "Over time you will learn the different and appropriate loss and optimizer functions for different scenarios. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8YQN1H41L-Y"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QyOUhFw1OUX"
   },
   "source": [
    "## Providing the Data\n",
    "\n",
    "Next up we'll feed in some data. In this case we are taking 6 xs and 6ys. You can see that the relationship between these is that y=2x-1, so where x = -1, y=-3 etc. etc. \n",
    "\n",
    "A python library called 'Numpy' provides lots of array type data structures that are a defacto standard way of doing it. We declare that we want to use these by specifying the values as an np.array[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Dxk4q-jzEy4"
   },
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_YcWRElnM_b"
   },
   "source": [
    "# Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-Jk4dG91dvD"
   },
   "source": [
    "The process of training the neural network, where it 'learns' the relationship between the Xs and Ys is in the **model.fit**  call. This is where it will go through the loop we spoke about above, making a guess, measuring how good or bad it is (aka the loss), using the opimizer to make another guess etc. It will do it for the number of epochs you specify. When you run this code, you'll see the loss on the right hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpRrl7WK10Pq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples\n",
      "Epoch 1/500\n",
      "6/6 [==============================] - 0s 28ms/sample - loss: 49.2942\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 344us/sample - loss: 39.1737\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 386us/sample - loss: 31.2033\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 743us/sample - loss: 24.9247\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 451us/sample - loss: 19.9773\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 16.0774\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 335us/sample - loss: 13.0017\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 10.5747\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 725us/sample - loss: 8.6581\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 528us/sample - loss: 7.1433\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 2ms/sample - loss: 5.9447\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 896us/sample - loss: 4.9950\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 625us/sample - loss: 4.2413\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 3.6420\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 2ms/sample - loss: 3.1642\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 665us/sample - loss: 2.7821\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 889us/sample - loss: 2.4755\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 2ms/sample - loss: 2.2284\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 735us/sample - loss: 2.0282\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 616us/sample - loss: 1.8651\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 416us/sample - loss: 1.7312\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 961us/sample - loss: 1.6204\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 287us/sample - loss: 1.5280\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 653us/sample - loss: 1.4501\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 747us/sample - loss: 1.3837\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 808us/sample - loss: 1.3264\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.2765\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 2ms/sample - loss: 1.2325\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.1931\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 308us/sample - loss: 1.1576\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.1251\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 2ms/sample - loss: 1.0952\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 469us/sample - loss: 1.0673\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 678us/sample - loss: 1.0412\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 341us/sample - loss: 1.0164\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 547us/sample - loss: 0.9929\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 418us/sample - loss: 0.9705\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 260us/sample - loss: 0.9489\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 382us/sample - loss: 0.9282\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.9081\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 402us/sample - loss: 0.8887\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 364us/sample - loss: 0.8698\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 313us/sample - loss: 0.8514\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 329us/sample - loss: 0.8336\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 434us/sample - loss: 0.8161\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 295us/sample - loss: 0.7991\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 377us/sample - loss: 0.7825\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 294us/sample - loss: 0.7663\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 459us/sample - loss: 0.7505\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 233us/sample - loss: 0.7349\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 358us/sample - loss: 0.7198\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 255us/sample - loss: 0.7049\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 319us/sample - loss: 0.6904\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 253us/sample - loss: 0.6762\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 310us/sample - loss: 0.6623\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 301us/sample - loss: 0.6487\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 251us/sample - loss: 0.6353\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 444us/sample - loss: 0.6223\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 268us/sample - loss: 0.6095\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 292us/sample - loss: 0.5969\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 503us/sample - loss: 0.5847\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 312us/sample - loss: 0.5726\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 211us/sample - loss: 0.5609\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 406us/sample - loss: 0.5494\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 383us/sample - loss: 0.5381\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 818us/sample - loss: 0.5270\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 553us/sample - loss: 0.5162\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 498us/sample - loss: 0.5056\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 511us/sample - loss: 0.4952\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.4850\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 426us/sample - loss: 0.4751\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 240us/sample - loss: 0.4653\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 305us/sample - loss: 0.4557\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 0.4464\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 355us/sample - loss: 0.4372\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 520us/sample - loss: 0.4282\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 369us/sample - loss: 0.4194\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 483us/sample - loss: 0.4108\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 339us/sample - loss: 0.4024\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 448us/sample - loss: 0.3941\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 348us/sample - loss: 0.3860\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 436us/sample - loss: 0.3781\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 407us/sample - loss: 0.3703\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 438us/sample - loss: 0.3627\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 410us/sample - loss: 0.3553\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 315us/sample - loss: 0.3480\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 270us/sample - loss: 0.3408\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 573us/sample - loss: 0.3338\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 389us/sample - loss: 0.3270\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 637us/sample - loss: 0.3203\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 487us/sample - loss: 0.3137\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 238us/sample - loss: 0.3072\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 0.3009\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 592us/sample - loss: 0.2947\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 451us/sample - loss: 0.2887\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 335us/sample - loss: 0.2828\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 395us/sample - loss: 0.2769\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 437us/sample - loss: 0.2713\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 343us/sample - loss: 0.2657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 430us/sample - loss: 0.2602\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 343us/sample - loss: 0.2549\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 336us/sample - loss: 0.2496\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 464us/sample - loss: 0.2445\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 491us/sample - loss: 0.2395\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 259us/sample - loss: 0.2346\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 285us/sample - loss: 0.2298\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 248us/sample - loss: 0.2250\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 318us/sample - loss: 0.2204\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 273us/sample - loss: 0.2159\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 327us/sample - loss: 0.2115\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 487us/sample - loss: 0.2071\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 251us/sample - loss: 0.2029\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 368us/sample - loss: 0.1987\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 464us/sample - loss: 0.1946\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 260us/sample - loss: 0.1906\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 200us/sample - loss: 0.1867\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 282us/sample - loss: 0.1829\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 382us/sample - loss: 0.1791\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 271us/sample - loss: 0.1754\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 390us/sample - loss: 0.1718\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 258us/sample - loss: 0.1683\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 506us/sample - loss: 0.1648\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 411us/sample - loss: 0.1615\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 268us/sample - loss: 0.1581\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 525us/sample - loss: 0.1549\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 281us/sample - loss: 0.1517\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 343us/sample - loss: 0.1486\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 363us/sample - loss: 0.1455\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 261us/sample - loss: 0.1425\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 337us/sample - loss: 0.1396\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 257us/sample - loss: 0.1368\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 330us/sample - loss: 0.1339\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 439us/sample - loss: 0.1312\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 307us/sample - loss: 0.1285\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 298us/sample - loss: 0.1259\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 188us/sample - loss: 0.1233\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 440us/sample - loss: 0.1207\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 233us/sample - loss: 0.1183\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 255us/sample - loss: 0.1158\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 325us/sample - loss: 0.1135\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 383us/sample - loss: 0.1111\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 313us/sample - loss: 0.1088\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 336us/sample - loss: 0.1066\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 286us/sample - loss: 0.1044\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 277us/sample - loss: 0.1023\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 234us/sample - loss: 0.1002\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 444us/sample - loss: 0.0981\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 433us/sample - loss: 0.0961\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 211us/sample - loss: 0.0941\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 221us/sample - loss: 0.0922\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 434us/sample - loss: 0.0903\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 343us/sample - loss: 0.0884\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 208us/sample - loss: 0.0866\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 224us/sample - loss: 0.0848\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 0.0831\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 455us/sample - loss: 0.0814\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 496us/sample - loss: 0.0797\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 204us/sample - loss: 0.0781\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 243us/sample - loss: 0.0765\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 308us/sample - loss: 0.0749\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 263us/sample - loss: 0.0734\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 266us/sample - loss: 0.0719\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 209us/sample - loss: 0.0704\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 225us/sample - loss: 0.0689\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 415us/sample - loss: 0.0675\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 256us/sample - loss: 0.0661\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 288us/sample - loss: 0.0648\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 261us/sample - loss: 0.0635\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 445us/sample - loss: 0.0621\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 300us/sample - loss: 0.0609\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 273us/sample - loss: 0.0596\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 236us/sample - loss: 0.0584\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 354us/sample - loss: 0.0572\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 464us/sample - loss: 0.0560\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 275us/sample - loss: 0.0549\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 263us/sample - loss: 0.0537\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 287us/sample - loss: 0.0526\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 296us/sample - loss: 0.0516\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 309us/sample - loss: 0.0505\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 308us/sample - loss: 0.0495\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 254us/sample - loss: 0.0484\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 253us/sample - loss: 0.0475\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0465\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 347us/sample - loss: 0.0455\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 198us/sample - loss: 0.0446\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 299us/sample - loss: 0.0437\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 0.0428\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 452us/sample - loss: 0.0419\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 246us/sample - loss: 0.0410\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 216us/sample - loss: 0.0402\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 210us/sample - loss: 0.0394\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 571us/sample - loss: 0.0386\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 381us/sample - loss: 0.0378\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 273us/sample - loss: 0.0370\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 214us/sample - loss: 0.0362\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 394us/sample - loss: 0.0355\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 301us/sample - loss: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 223us/sample - loss: 0.0340\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 217us/sample - loss: 0.0333\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 383us/sample - loss: 0.0327\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 379us/sample - loss: 0.0320\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 481us/sample - loss: 0.0313\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 713us/sample - loss: 0.0307\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 247us/sample - loss: 0.0301\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 392us/sample - loss: 0.0294\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 744us/sample - loss: 0.0288\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 364us/sample - loss: 0.0282\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 682us/sample - loss: 0.0277\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 906us/sample - loss: 0.0271\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 297us/sample - loss: 0.0265\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 892us/sample - loss: 0.0260\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 655us/sample - loss: 0.0255\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 465us/sample - loss: 0.0249\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 726us/sample - loss: 0.0244\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 527us/sample - loss: 0.0239\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0234\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 248us/sample - loss: 0.0229\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 569us/sample - loss: 0.0225\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 584us/sample - loss: 0.0220\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0216\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 596us/sample - loss: 0.0211\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 744us/sample - loss: 0.0207\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 186us/sample - loss: 0.0203\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 230us/sample - loss: 0.0198\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 606us/sample - loss: 0.0194\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 241us/sample - loss: 0.0190\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 280us/sample - loss: 0.0186\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 672us/sample - loss: 0.0183\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 285us/sample - loss: 0.0179\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 637us/sample - loss: 0.0175\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 573us/sample - loss: 0.0172\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 399us/sample - loss: 0.0168\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 253us/sample - loss: 0.0165\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 631us/sample - loss: 0.0161\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 534us/sample - loss: 0.0158\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 305us/sample - loss: 0.0155\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 292us/sample - loss: 0.0152\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 224us/sample - loss: 0.0148\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 259us/sample - loss: 0.0145\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 623us/sample - loss: 0.0142\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 344us/sample - loss: 0.0139\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 348us/sample - loss: 0.0137\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 615us/sample - loss: 0.0134\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0131\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 544us/sample - loss: 0.0128\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 351us/sample - loss: 0.0126\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 280us/sample - loss: 0.0123\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 506us/sample - loss: 0.0121\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 255us/sample - loss: 0.0118\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 267us/sample - loss: 0.0116\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 252us/sample - loss: 0.0113\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 530us/sample - loss: 0.0111\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 303us/sample - loss: 0.0109\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 413us/sample - loss: 0.0106\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 247us/sample - loss: 0.0104\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 311us/sample - loss: 0.0102\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 375us/sample - loss: 0.0100\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 505us/sample - loss: 0.0098\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 0.0096\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 373us/sample - loss: 0.0094\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 244us/sample - loss: 0.0092\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 261us/sample - loss: 0.0090\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 0.0088\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 285us/sample - loss: 0.0087\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 220us/sample - loss: 0.0085\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 254us/sample - loss: 0.0083\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 258us/sample - loss: 0.0081\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 470us/sample - loss: 0.0080\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 327us/sample - loss: 0.0078\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 286us/sample - loss: 0.0076\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 235us/sample - loss: 0.0075\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 686us/sample - loss: 0.0073\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 526us/sample - loss: 0.0072\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 241us/sample - loss: 0.0070\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 298us/sample - loss: 0.0069\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 357us/sample - loss: 0.0067\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 404us/sample - loss: 0.0066\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 357us/sample - loss: 0.0065\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 549us/sample - loss: 0.0063\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 236us/sample - loss: 0.0062\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 220us/sample - loss: 0.0061\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 283us/sample - loss: 0.0060\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 210us/sample - loss: 0.0058\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 352us/sample - loss: 0.0057\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 266us/sample - loss: 0.0056\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 218us/sample - loss: 0.0055\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 231us/sample - loss: 0.0054\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 462us/sample - loss: 0.0053\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 262us/sample - loss: 0.0051\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 253us/sample - loss: 0.0050\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 243us/sample - loss: 0.0049\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 204us/sample - loss: 0.0048\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 248us/sample - loss: 0.0047\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 362us/sample - loss: 0.0046\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 385us/sample - loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 208us/sample - loss: 0.0045\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 211us/sample - loss: 0.0044\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 0.0043\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 363us/sample - loss: 0.0042\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 214us/sample - loss: 0.0041\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 229us/sample - loss: 0.0040\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 248us/sample - loss: 0.0039\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 267us/sample - loss: 0.0039\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 391us/sample - loss: 0.0038\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 288us/sample - loss: 0.0037\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 243us/sample - loss: 0.0036\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 237us/sample - loss: 0.0035\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 255us/sample - loss: 0.0035\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 368us/sample - loss: 0.0034\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 276us/sample - loss: 0.0033\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 215us/sample - loss: 0.0033\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 444us/sample - loss: 0.0032\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 763us/sample - loss: 0.0031\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 256us/sample - loss: 0.0031\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 310us/sample - loss: 0.0030\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 223us/sample - loss: 0.0029\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 300us/sample - loss: 0.0029\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 280us/sample - loss: 0.0028\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 0.0028\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 243us/sample - loss: 0.0027\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 372us/sample - loss: 0.0027\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.0026\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 308us/sample - loss: 0.0025\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 235us/sample - loss: 0.0025\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 322us/sample - loss: 0.0024\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 275us/sample - loss: 0.0024\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 275us/sample - loss: 0.0023\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 265us/sample - loss: 0.0023\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 404us/sample - loss: 0.0022\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 372us/sample - loss: 0.0022\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 189us/sample - loss: 0.0022\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 271us/sample - loss: 0.0021\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 257us/sample - loss: 0.0021\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 404us/sample - loss: 0.0020\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 213us/sample - loss: 0.0020\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 253us/sample - loss: 0.0019\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 292us/sample - loss: 0.0019\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 591us/sample - loss: 0.0019\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 311us/sample - loss: 0.0018\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 0.0018\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 0.0018\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 261us/sample - loss: 0.0017\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 396us/sample - loss: 0.0017\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 317us/sample - loss: 0.0016\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 250us/sample - loss: 0.0016\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 259us/sample - loss: 0.0016\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 260us/sample - loss: 0.0015\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 259us/sample - loss: 0.0015\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 238us/sample - loss: 0.0015\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 305us/sample - loss: 0.0015\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 205us/sample - loss: 0.0014\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 342us/sample - loss: 0.0014\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 361us/sample - loss: 0.0014\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 209us/sample - loss: 0.0013\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 256us/sample - loss: 0.0013\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 285us/sample - loss: 0.0013\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 313us/sample - loss: 0.0013\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 211us/sample - loss: 0.0012\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 0.0012\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 262us/sample - loss: 0.0012\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 553us/sample - loss: 0.0012\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 343us/sample - loss: 0.0011\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 234us/sample - loss: 0.0011\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 202us/sample - loss: 0.0011\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 376us/sample - loss: 0.0011\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 409us/sample - loss: 0.0010\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 381us/sample - loss: 0.0010\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 254us/sample - loss: 9.9937e-04\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 317us/sample - loss: 9.7884e-04\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 316us/sample - loss: 9.5873e-04\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 405us/sample - loss: 9.3904e-04\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 223us/sample - loss: 9.1975e-04\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 236us/sample - loss: 9.0086e-04\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 229us/sample - loss: 8.8236e-04\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 369us/sample - loss: 8.6423e-04\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 447us/sample - loss: 8.4648e-04\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 377us/sample - loss: 8.2910e-04\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 198us/sample - loss: 8.1207e-04\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 268us/sample - loss: 7.9539e-04\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 327us/sample - loss: 7.7905e-04\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 377us/sample - loss: 7.6304e-04\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 241us/sample - loss: 7.4737e-04\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 223us/sample - loss: 7.3202e-04\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 324us/sample - loss: 7.1698e-04\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 410us/sample - loss: 7.0226e-04\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 270us/sample - loss: 6.8783e-04\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 302us/sample - loss: 6.7371e-04\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 460us/sample - loss: 6.5987e-04\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 6.4631e-04\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 393us/sample - loss: 6.3304e-04\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 281us/sample - loss: 6.2004e-04\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 256us/sample - loss: 6.0730e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 327us/sample - loss: 5.9482e-04\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 330us/sample - loss: 5.8260e-04\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 345us/sample - loss: 5.7064e-04\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 480us/sample - loss: 5.5891e-04\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 5.4744e-04\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 245us/sample - loss: 5.3619e-04\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 358us/sample - loss: 5.2518e-04\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 339us/sample - loss: 5.1439e-04\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 675us/sample - loss: 5.0382e-04\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 380us/sample - loss: 4.9347e-04\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 4.8334e-04\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 264us/sample - loss: 4.7341e-04\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 362us/sample - loss: 4.6369e-04\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 350us/sample - loss: 4.5416e-04\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 328us/sample - loss: 4.4483e-04\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 263us/sample - loss: 4.3570e-04\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 260us/sample - loss: 4.2675e-04\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 303us/sample - loss: 4.1798e-04\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 309us/sample - loss: 4.0939e-04\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 207us/sample - loss: 4.0098e-04\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 218us/sample - loss: 3.9275e-04\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 227us/sample - loss: 3.8468e-04\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 268us/sample - loss: 3.7678e-04\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 305us/sample - loss: 3.6904e-04\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 328us/sample - loss: 3.6146e-04\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 217us/sample - loss: 3.5404e-04\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 300us/sample - loss: 3.4677e-04\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 284us/sample - loss: 3.3964e-04\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 526us/sample - loss: 3.3266e-04\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 290us/sample - loss: 3.2583e-04\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 202us/sample - loss: 3.1914e-04\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 194us/sample - loss: 3.1258e-04\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 206us/sample - loss: 3.0616e-04\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 258us/sample - loss: 2.9988e-04\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 281us/sample - loss: 2.9372e-04\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 265us/sample - loss: 2.8768e-04\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 238us/sample - loss: 2.8177e-04\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 273us/sample - loss: 2.7599e-04\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 339us/sample - loss: 2.7032e-04\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 517us/sample - loss: 2.6476e-04\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 329us/sample - loss: 2.5933e-04\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 249us/sample - loss: 2.5400e-04\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 250us/sample - loss: 2.4878e-04\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 328us/sample - loss: 2.4367e-04\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 398us/sample - loss: 2.3867e-04\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 232us/sample - loss: 2.3376e-04\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 303us/sample - loss: 2.2896e-04\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 235us/sample - loss: 2.2426e-04\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 312us/sample - loss: 2.1965e-04\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 320us/sample - loss: 2.1514e-04\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 238us/sample - loss: 2.1072e-04\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 201us/sample - loss: 2.0639e-04\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 418us/sample - loss: 2.0215e-04\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 310us/sample - loss: 1.9800e-04\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 271us/sample - loss: 1.9393e-04\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 208us/sample - loss: 1.8995e-04\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 198us/sample - loss: 1.8605e-04\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 226us/sample - loss: 1.8223e-04\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 366us/sample - loss: 1.7848e-04\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 369us/sample - loss: 1.7482e-04\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 247us/sample - loss: 1.7123e-04\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 232us/sample - loss: 1.6771e-04\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 321us/sample - loss: 1.6426e-04\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 302us/sample - loss: 1.6089e-04\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 208us/sample - loss: 1.5759e-04\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 369us/sample - loss: 1.5435e-04\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 286us/sample - loss: 1.5118e-04\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 322us/sample - loss: 1.4807e-04\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 435us/sample - loss: 1.4503e-04\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 241us/sample - loss: 1.4205e-04\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 401us/sample - loss: 1.3913e-04\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 344us/sample - loss: 1.3628e-04\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 278us/sample - loss: 1.3348e-04\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 427us/sample - loss: 1.3073e-04\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 361us/sample - loss: 1.2805e-04\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 390us/sample - loss: 1.2542e-04\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 304us/sample - loss: 1.2284e-04\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 251us/sample - loss: 1.2032e-04\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 278us/sample - loss: 1.1785e-04\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 437us/sample - loss: 1.1543e-04\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 305us/sample - loss: 1.1306e-04\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 299us/sample - loss: 1.1073e-04\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 439us/sample - loss: 1.0846e-04\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 274us/sample - loss: 1.0623e-04\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 250us/sample - loss: 1.0405e-04\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 281us/sample - loss: 1.0191e-04\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 300us/sample - loss: 9.9821e-05\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 484us/sample - loss: 9.7771e-05\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 200us/sample - loss: 9.5762e-05\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 264us/sample - loss: 9.3794e-05\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 9.1869e-05\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 243us/sample - loss: 8.9982e-05\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 365us/sample - loss: 8.8133e-05\n",
      "Epoch 486/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 493us/sample - loss: 8.6323e-05\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 361us/sample - loss: 8.4550e-05\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 269us/sample - loss: 8.2813e-05\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 534us/sample - loss: 8.1111e-05\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 356us/sample - loss: 7.9446e-05\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 269us/sample - loss: 7.7814e-05\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 316us/sample - loss: 7.6216e-05\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 493us/sample - loss: 7.4649e-05\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 387us/sample - loss: 7.3117e-05\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 7.1614e-05\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 263us/sample - loss: 7.0143e-05\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 458us/sample - loss: 6.8703e-05\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 289us/sample - loss: 6.7291e-05\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 256us/sample - loss: 6.5909e-05\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 275us/sample - loss: 6.4556e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1320b0990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaFIr71H2OZ-"
   },
   "source": [
    "Ok, now you have a model that has been trained to learn the relationshop between X and Y. You can use the **model.predict** method to have it figure out the Y for a previously unknown X. So, for example, if X = 10, what do you think Y will be? Take a guess before you run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxNzL4lS2Gui"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.976559]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btF2CSFH2iEX"
   },
   "source": [
    "You might have thought 19, right? But it ended up being a little under. Why do you think that is? \n",
    "\n",
    "Remember that neural networks deal with probabilities, so given the data that we fed the NN with, it calculated that there is a very high probability that the relationship between X and Y is Y=2X-1, but with only 6 data points we can't know for sure. As a result, the result for 10 is very close to 19, but not necessarily 19. \n",
    "\n",
    "As you work with neural networks, you'll see this pattern recurring. You will almost always deal with probabilities, not certainties, and will do a little bit of coding to figure out what the result is based on the probabilities, particularly when it comes to classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting loss vs epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [49.29420471191406,\n",
       "  39.173683166503906,\n",
       "  31.20330238342285,\n",
       "  24.92472267150879,\n",
       "  19.977325439453125,\n",
       "  16.077394485473633,\n",
       "  13.001720428466797,\n",
       "  10.57468318939209,\n",
       "  8.658108711242676,\n",
       "  7.143287658691406,\n",
       "  5.944690227508545,\n",
       "  4.995022773742676,\n",
       "  4.241337299346924,\n",
       "  3.6419761180877686,\n",
       "  3.1641604900360107,\n",
       "  2.782099962234497,\n",
       "  2.475501775741577,\n",
       "  2.22839617729187,\n",
       "  2.0282175540924072,\n",
       "  1.8650776147842407,\n",
       "  1.7311941385269165,\n",
       "  1.6204410791397095,\n",
       "  1.5279980897903442,\n",
       "  1.450069546699524,\n",
       "  1.3836663961410522,\n",
       "  1.326436161994934,\n",
       "  1.2765249013900757,\n",
       "  1.2324719429016113,\n",
       "  1.1931267976760864,\n",
       "  1.1575816869735718,\n",
       "  1.1251202821731567,\n",
       "  1.0951775312423706,\n",
       "  1.067306637763977,\n",
       "  1.0411547422409058,\n",
       "  1.0164417028427124,\n",
       "  0.9929458498954773,\n",
       "  0.9704905152320862,\n",
       "  0.9489358067512512,\n",
       "  0.9281694889068604,\n",
       "  0.9081013202667236,\n",
       "  0.8886592388153076,\n",
       "  0.8697848916053772,\n",
       "  0.8514306545257568,\n",
       "  0.8335574269294739,\n",
       "  0.8161333203315735,\n",
       "  0.7991318106651306,\n",
       "  0.7825300097465515,\n",
       "  0.7663090825080872,\n",
       "  0.7504526972770691,\n",
       "  0.7349469065666199,\n",
       "  0.7197789549827576,\n",
       "  0.704937756061554,\n",
       "  0.6904137134552002,\n",
       "  0.6761972904205322,\n",
       "  0.662280261516571,\n",
       "  0.6486549973487854,\n",
       "  0.6353141665458679,\n",
       "  0.6222512125968933,\n",
       "  0.6094591617584229,\n",
       "  0.5969322919845581,\n",
       "  0.5846643447875977,\n",
       "  0.5726499557495117,\n",
       "  0.5608833432197571,\n",
       "  0.5493592619895935,\n",
       "  0.5380725860595703,\n",
       "  0.5270182490348816,\n",
       "  0.5161914229393005,\n",
       "  0.5055872797966003,\n",
       "  0.4952012598514557,\n",
       "  0.48502886295318604,\n",
       "  0.4750654399394989,\n",
       "  0.4653068482875824,\n",
       "  0.45574888586997986,\n",
       "  0.4463872015476227,\n",
       "  0.43721792101860046,\n",
       "  0.42823705077171326,\n",
       "  0.4194405972957611,\n",
       "  0.4108249247074127,\n",
       "  0.40238621830940247,\n",
       "  0.3941209018230438,\n",
       "  0.38602542877197266,\n",
       "  0.3780961036682129,\n",
       "  0.37032976746559143,\n",
       "  0.3627229630947113,\n",
       "  0.3552723824977875,\n",
       "  0.34797486662864685,\n",
       "  0.34082719683647156,\n",
       "  0.3338264226913452,\n",
       "  0.3269694149494171,\n",
       "  0.32025328278541565,\n",
       "  0.31367507576942444,\n",
       "  0.30723196268081665,\n",
       "  0.300921231508255,\n",
       "  0.29474011063575745,\n",
       "  0.28868594765663147,\n",
       "  0.2827562093734741,\n",
       "  0.2769482135772705,\n",
       "  0.27125948667526245,\n",
       "  0.2656876742839813,\n",
       "  0.26023027300834656,\n",
       "  0.2548849880695343,\n",
       "  0.2496495246887207,\n",
       "  0.24452157318592072,\n",
       "  0.23949895799160004,\n",
       "  0.23457945883274078,\n",
       "  0.22976112365722656,\n",
       "  0.22504167258739471,\n",
       "  0.22041909396648407,\n",
       "  0.21589158475399017,\n",
       "  0.2114570140838623,\n",
       "  0.207113578915596,\n",
       "  0.20285938680171967,\n",
       "  0.1986924409866333,\n",
       "  0.19461123645305634,\n",
       "  0.1906137317419052,\n",
       "  0.18669839203357697,\n",
       "  0.18286354839801788,\n",
       "  0.1791074126958847,\n",
       "  0.1754283905029297,\n",
       "  0.17182499170303345,\n",
       "  0.16829563677310944,\n",
       "  0.1648387312889099,\n",
       "  0.16145282983779907,\n",
       "  0.1581365168094635,\n",
       "  0.15488828718662262,\n",
       "  0.1517067402601242,\n",
       "  0.14859060943126678,\n",
       "  0.14553849399089813,\n",
       "  0.142549067735672,\n",
       "  0.13962098956108093,\n",
       "  0.13675306737422943,\n",
       "  0.1339440792798996,\n",
       "  0.13119280338287354,\n",
       "  0.12849800288677216,\n",
       "  0.1258586049079895,\n",
       "  0.12327340990304947,\n",
       "  0.12074128538370132,\n",
       "  0.11826121807098389,\n",
       "  0.11583203822374344,\n",
       "  0.11345276236534119,\n",
       "  0.11112240701913834,\n",
       "  0.10883989930152893,\n",
       "  0.10660424083471298,\n",
       "  0.10441454499959946,\n",
       "  0.10226977616548538,\n",
       "  0.1001691222190857,\n",
       "  0.09811156243085861,\n",
       "  0.09609630703926086,\n",
       "  0.09412240982055664,\n",
       "  0.09218911081552505,\n",
       "  0.0902954712510109,\n",
       "  0.08844077587127686,\n",
       "  0.0866241380572319,\n",
       "  0.08484482765197754,\n",
       "  0.08310208469629288,\n",
       "  0.08139507472515106,\n",
       "  0.07972321659326553,\n",
       "  0.07808566838502884,\n",
       "  0.07648169249296188,\n",
       "  0.0749107226729393,\n",
       "  0.07337202876806259,\n",
       "  0.07186489552259445,\n",
       "  0.07038873434066772,\n",
       "  0.06894292682409286,\n",
       "  0.06752676516771317,\n",
       "  0.06613970547914505,\n",
       "  0.06478115916252136,\n",
       "  0.06345051527023315,\n",
       "  0.06214722990989685,\n",
       "  0.0608706958591938,\n",
       "  0.05962036922574043,\n",
       "  0.05839572846889496,\n",
       "  0.057196225970983505,\n",
       "  0.05602139234542847,\n",
       "  0.054870665073394775,\n",
       "  0.053743597120046616,\n",
       "  0.0526396669447422,\n",
       "  0.05155840516090393,\n",
       "  0.050499364733695984,\n",
       "  0.04946208372712135,\n",
       "  0.048446107655763626,\n",
       "  0.04745100066065788,\n",
       "  0.04647631570696831,\n",
       "  0.04552166163921356,\n",
       "  0.04458663985133171,\n",
       "  0.04367079213261604,\n",
       "  0.042773764580488205,\n",
       "  0.04189517721533775,\n",
       "  0.041034627705812454,\n",
       "  0.04019173979759216,\n",
       "  0.03936617821455002,\n",
       "  0.03855758532881737,\n",
       "  0.037765588611364365,\n",
       "  0.036989834159612656,\n",
       "  0.036230046302080154,\n",
       "  0.03548583760857582,\n",
       "  0.03475695103406906,\n",
       "  0.034043047577142715,\n",
       "  0.033343762159347534,\n",
       "  0.03265887126326561,\n",
       "  0.03198804333806038,\n",
       "  0.03133097290992737,\n",
       "  0.030687443912029266,\n",
       "  0.03005710244178772,\n",
       "  0.02943970263004303,\n",
       "  0.02883499301970005,\n",
       "  0.0282426867634058,\n",
       "  0.027662575244903564,\n",
       "  0.027094366028904915,\n",
       "  0.026537830010056496,\n",
       "  0.02599272131919861,\n",
       "  0.025458822026848793,\n",
       "  0.02493588626384735,\n",
       "  0.02442367561161518,\n",
       "  0.023921996355056763,\n",
       "  0.02343062311410904,\n",
       "  0.02294933795928955,\n",
       "  0.022477945312857628,\n",
       "  0.0220162495970726,\n",
       "  0.02156403847038746,\n",
       "  0.021121090278029442,\n",
       "  0.020687252283096313,\n",
       "  0.020262310281395912,\n",
       "  0.019846120849251747,\n",
       "  0.019438467919826508,\n",
       "  0.019039181992411613,\n",
       "  0.018648110330104828,\n",
       "  0.018265070393681526,\n",
       "  0.017889874055981636,\n",
       "  0.017522398382425308,\n",
       "  0.017162492498755455,\n",
       "  0.016809964552521706,\n",
       "  0.016464682295918465,\n",
       "  0.01612648367881775,\n",
       "  0.01579522155225277,\n",
       "  0.0154707757756114,\n",
       "  0.015153010375797749,\n",
       "  0.014841758646070957,\n",
       "  0.014536894857883453,\n",
       "  0.014238306321203709,\n",
       "  0.013945836573839188,\n",
       "  0.013659398071467876,\n",
       "  0.013378799892961979,\n",
       "  0.013104005716741085,\n",
       "  0.012834839522838593,\n",
       "  0.012571204453706741,\n",
       "  0.012312968261539936,\n",
       "  0.012060047127306461,\n",
       "  0.011812339536845684,\n",
       "  0.011569698341190815,\n",
       "  0.011332061141729355,\n",
       "  0.01109927985817194,\n",
       "  0.010871301405131817,\n",
       "  0.010647986084222794,\n",
       "  0.010429282672703266,\n",
       "  0.010215059854090214,\n",
       "  0.010005220770835876,\n",
       "  0.00979971420019865,\n",
       "  0.009598429314792156,\n",
       "  0.00940126646310091,\n",
       "  0.009208151139318943,\n",
       "  0.009019020013511181,\n",
       "  0.008833765052258968,\n",
       "  0.00865231454372406,\n",
       "  0.008474579080939293,\n",
       "  0.008300513960421085,\n",
       "  0.008130006492137909,\n",
       "  0.007963025942444801,\n",
       "  0.007799448911100626,\n",
       "  0.007639253977686167,\n",
       "  0.0074823456816375256,\n",
       "  0.007328651379793882,\n",
       "  0.007178116589784622,\n",
       "  0.007030662149190903,\n",
       "  0.006886256393045187,\n",
       "  0.006744811311364174,\n",
       "  0.006606257054954767,\n",
       "  0.006470566149801016,\n",
       "  0.006337656173855066,\n",
       "  0.006207480560988188,\n",
       "  0.006079971790313721,\n",
       "  0.005955083761364222,\n",
       "  0.00583276292309165,\n",
       "  0.0057129692286252975,\n",
       "  0.005595613270998001,\n",
       "  0.005480673164129257,\n",
       "  0.005368094425648451,\n",
       "  0.005257831420749426,\n",
       "  0.0051498436369001865,\n",
       "  0.005044059827923775,\n",
       "  0.004940446000546217,\n",
       "  0.004838962573558092,\n",
       "  0.004739571362733841,\n",
       "  0.0046422225423157215,\n",
       "  0.004546863492578268,\n",
       "  0.004453472327440977,\n",
       "  0.004362000618129969,\n",
       "  0.0042723920196294785,\n",
       "  0.004184637684375048,\n",
       "  0.004098677542060614,\n",
       "  0.004014491569250822,\n",
       "  0.003932024817913771,\n",
       "  0.00385125819593668,\n",
       "  0.0037721581757068634,\n",
       "  0.0036946770269423723,\n",
       "  0.003618789603933692,\n",
       "  0.0035444486420601606,\n",
       "  0.0034716466907411814,\n",
       "  0.003400345565751195,\n",
       "  0.0033304961398243904,\n",
       "  0.003262086072936654,\n",
       "  0.003195082535967231,\n",
       "  0.0031294478103518486,\n",
       "  0.0030651718843728304,\n",
       "  0.003002211218699813,\n",
       "  0.002940540434792638,\n",
       "  0.0028801446314901114,\n",
       "  0.002820987021550536,\n",
       "  0.0027630457188934088,\n",
       "  0.002706284634768963,\n",
       "  0.0026506998110562563,\n",
       "  0.0025962505023926497,\n",
       "  0.0025429234374314547,\n",
       "  0.0024906944017857313,\n",
       "  0.0024395326618105173,\n",
       "  0.0023894242476671934,\n",
       "  0.0023403377272188663,\n",
       "  0.0022922733332961798,\n",
       "  0.0022451812401413918,\n",
       "  0.0021990665700286627,\n",
       "  0.0021538997534662485,\n",
       "  0.0021096549462527037,\n",
       "  0.0020663237664848566,\n",
       "  0.00202388153411448,\n",
       "  0.0019823082257062197,\n",
       "  0.0019415938295423985,\n",
       "  0.0019017154118046165,\n",
       "  0.0018626466626301408,\n",
       "  0.0018243881640955806,\n",
       "  0.001786914304830134,\n",
       "  0.0017502069240435958,\n",
       "  0.0017142611322924495,\n",
       "  0.0016790508525446057,\n",
       "  0.0016445658402517438,\n",
       "  0.0016107866540551186,\n",
       "  0.00157769990619272,\n",
       "  0.0015452938387170434,\n",
       "  0.001513552968390286,\n",
       "  0.0014824591344222426,\n",
       "  0.0014520129188895226,\n",
       "  0.0014221859164536,\n",
       "  0.001392972539179027,\n",
       "  0.0013643610291182995,\n",
       "  0.0013363356702029705,\n",
       "  0.001308887847699225,\n",
       "  0.0012819991679862142,\n",
       "  0.0012556625297293067,\n",
       "  0.0012298697838559747,\n",
       "  0.0012046103365719318,\n",
       "  0.0011798724299296737,\n",
       "  0.0011556352255865932,\n",
       "  0.001131896278820932,\n",
       "  0.0011086479062214494,\n",
       "  0.0010858727619051933,\n",
       "  0.0010635723592713475,\n",
       "  0.0010417272569611669,\n",
       "  0.0010203258134424686,\n",
       "  0.000999368610791862,\n",
       "  0.0009788433089852333,\n",
       "  0.000958732794970274,\n",
       "  0.0009390396880917251,\n",
       "  0.0009197507170028985,\n",
       "  0.00090086116688326,\n",
       "  0.0008823605603538454,\n",
       "  0.0008642345783300698,\n",
       "  0.0008464836864732206,\n",
       "  0.0008290954283438623,\n",
       "  0.0008120664278976619,\n",
       "  0.0007953902240842581,\n",
       "  0.0007790494710206985,\n",
       "  0.0007630440522916615,\n",
       "  0.0007473736186511815,\n",
       "  0.0007320221629925072,\n",
       "  0.0007169824093580246,\n",
       "  0.0007022570935077965,\n",
       "  0.0006878345739096403,\n",
       "  0.0006737068761140108,\n",
       "  0.0006598692270927131,\n",
       "  0.0006463121972046793,\n",
       "  0.0006330389878712595,\n",
       "  0.0006200355128385127,\n",
       "  0.0006072989199310541,\n",
       "  0.0005948226898908615,\n",
       "  0.0005826039123348892,\n",
       "  0.0005706402589567006,\n",
       "  0.000558914674911648,\n",
       "  0.0005474365898407996,\n",
       "  0.000536191975697875,\n",
       "  0.0005251762340776622,\n",
       "  0.0005143907037563622,\n",
       "  0.0005038222880102694,\n",
       "  0.0004934733733534813,\n",
       "  0.0004833378770854324,\n",
       "  0.0004734086978714913,\n",
       "  0.00046368708717636764,\n",
       "  0.00045416050124913454,\n",
       "  0.00044483167584985495,\n",
       "  0.00043569764238782227,\n",
       "  0.00042674868018366396,\n",
       "  0.00041798033635132015,\n",
       "  0.00040939441532827914,\n",
       "  0.0004009846888948232,\n",
       "  0.0003927488287445158,\n",
       "  0.0003846831095870584,\n",
       "  0.00037678066291846335,\n",
       "  0.00036904215812683105,\n",
       "  0.0003614602901507169,\n",
       "  0.00035403555375523865,\n",
       "  0.0003467651840765029,\n",
       "  0.000339641235768795,\n",
       "  0.0003326646110508591,\n",
       "  0.0003258306242059916,\n",
       "  0.0003191387513652444,\n",
       "  0.00031258337548933923,\n",
       "  0.0003061635361518711,\n",
       "  0.00029987600282765925,\n",
       "  0.000293715886073187,\n",
       "  0.0002876818471122533,\n",
       "  0.00028177318745292723,\n",
       "  0.00027598629822023213,\n",
       "  0.00027031719218939543,\n",
       "  0.0002647634537424892,\n",
       "  0.00025932627613656223,\n",
       "  0.0002539977722335607,\n",
       "  0.0002487809397280216,\n",
       "  0.0002436695504002273,\n",
       "  0.00023866543779149652,\n",
       "  0.00023376305762212723,\n",
       "  0.00022896002337802202,\n",
       "  0.00022425655333790928,\n",
       "  0.0002196510467911139,\n",
       "  0.00021514004038181156,\n",
       "  0.00021071934315841645,\n",
       "  0.0002063922438537702,\n",
       "  0.0002021526452153921,\n",
       "  0.00019800062000285834,\n",
       "  0.00019393286493141204,\n",
       "  0.00018995032587554306,\n",
       "  0.00018604780780151486,\n",
       "  0.00018222506332676858,\n",
       "  0.00017848187417257577,\n",
       "  0.00017481634858995676,\n",
       "  0.00017122516874223948,\n",
       "  0.00016770792717579752,\n",
       "  0.00016426376532763243,\n",
       "  0.00016089047130662948,\n",
       "  0.00015758530935272574,\n",
       "  0.0001543498074170202,\n",
       "  0.000151178814121522,\n",
       "  0.00014807215484324843,\n",
       "  0.00014503065904136747,\n",
       "  0.00014205322077032179,\n",
       "  0.00013913384464103729,\n",
       "  0.00013627736188936979,\n",
       "  0.00013347760250326246,\n",
       "  0.00013073478476144373,\n",
       "  0.00012805000005755574,\n",
       "  0.0001254207018064335,\n",
       "  0.00012284365948289633,\n",
       "  0.00012031954247504473,\n",
       "  0.00011784828529926017,\n",
       "  0.00011542663560248911,\n",
       "  0.00011305795487714931,\n",
       "  0.00011073437053710222,\n",
       "  0.0001084597097360529,\n",
       "  0.00010623400885378942,\n",
       "  0.0001040519928210415,\n",
       "  0.00010191447654506192,\n",
       "  9.982124902307987e-05,\n",
       "  9.77706877165474e-05,\n",
       "  9.576211596140638e-05,\n",
       "  9.379392577102408e-05,\n",
       "  9.186880924971774e-05,\n",
       "  8.998184785014018e-05,\n",
       "  8.813318709144369e-05,\n",
       "  8.632268145447597e-05,\n",
       "  8.454980707028881e-05,\n",
       "  8.281305781565607e-05,\n",
       "  8.111120405374095e-05,\n",
       "  7.944602839415893e-05,\n",
       "  7.781395834172145e-05,\n",
       "  7.621575059602037e-05,\n",
       "  7.464939699275419e-05,\n",
       "  7.31170002836734e-05,\n",
       "  7.16143476893194e-05,\n",
       "  7.014290167717263e-05,\n",
       "  6.870285869808868e-05,\n",
       "  6.729128654114902e-05,\n",
       "  6.590923294425011e-05,\n",
       "  6.455556285800412e-05]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this we can remove the training epochs to around 150 as it almost got saturated after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Colab1-for-deeplearn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
